{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38679a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "\n",
    "from args import get_test_args\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "from json import dumps\n",
    "from models import BiDAF, QANet, UnifiedQANet\n",
    "from os.path import join\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from ujson import load as json_load\n",
    "from util import collate_fn, SQuAD, metric_max_over_ground_truths, compute_em, compute_f1, compute_avna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e48176",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SQuAD('./data/train.npz', True)\n",
    "dev_dataset = SQuAD('./data/dev.npz', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04f82cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = util.torch_from_json('./data/word_emb.json')\n",
    "char_vectors = util.torch_from_json('./data/char_emb.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded80ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([88714, 300])\n",
      "torch.Size([1376, 64])\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.shape)\n",
    "print(char_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "e1027f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/word2idx.json', \"r\") as fh:\n",
    "    word2idx = json.load(fh)\n",
    "idx2word = {v: k for k, v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "c0ce9d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_idx = dev_dataset.context_idxs[0]\n",
    "\n",
    "def idx_to_context(context_idx):\n",
    "    tmp = [idx2word[idx.item()] for idx in context_idx]\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "743d7f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35, 22, 56,  ...,  0,  0,  0])"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_dataset.y1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "4d79be32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'when',\n",
       " 'from',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'when',\n",
       " 'who',\n",
       " 'who',\n",
       " 'what',\n",
       " 'what',\n",
       " 'who',\n",
       " 'who',\n",
       " 'who',\n",
       " 'what',\n",
       " 'what',\n",
       " 'when',\n",
       " 'what',\n",
       " 'when',\n",
       " 'when',\n",
       " 'who',\n",
       " 'what',\n",
       " 'when',\n",
       " 'what',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'when',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'who',\n",
       " 'who',\n",
       " 'who',\n",
       " 'who',\n",
       " 'during',\n",
       " 'when',\n",
       " 'when',\n",
       " 'who',\n",
       " 'who',\n",
       " 'when',\n",
       " 'who',\n",
       " 'when',\n",
       " 'what',\n",
       " 'who',\n",
       " 'who',\n",
       " 'who',\n",
       " 'who',\n",
       " 'what',\n",
       " 'where',\n",
       " 'what',\n",
       " 'where',\n",
       " 'who',\n",
       " 'what',\n",
       " 'what',\n",
       " 'when',\n",
       " 'how',\n",
       " 'who',\n",
       " 'what',\n",
       " 'what',\n",
       " 'how',\n",
       " 'where',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'who',\n",
       " 'who',\n",
       " 'when',\n",
       " 'what',\n",
       " 'where',\n",
       " 'who',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'who',\n",
       " 'to',\n",
       " 'who',\n",
       " 'who',\n",
       " 'when',\n",
       " 'who',\n",
       " 'who',\n",
       " 'when',\n",
       " 'who',\n",
       " 'when',\n",
       " 'what',\n",
       " 'who',\n",
       " 'where',\n",
       " 'who',\n",
       " 'when',\n",
       " 'who',\n",
       " 'when',\n",
       " 'what',\n",
       " 'who',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'in',\n",
       " 'what',\n",
       " 'what',\n",
       " 'where',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'who',\n",
       " 'when',\n",
       " 'who',\n",
       " 'who',\n",
       " 'who',\n",
       " 'who',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'what',\n",
       " 'where',\n",
       " 'who',\n",
       " 'who',\n",
       " 'who',\n",
       " 'who',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'who',\n",
       " 'where',\n",
       " 'what',\n",
       " 'who',\n",
       " 'what',\n",
       " 'when',\n",
       " 'what',\n",
       " 'what',\n",
       " 'when',\n",
       " 'what',\n",
       " 'how',\n",
       " 'who',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'who',\n",
       " 'who',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'who',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'where',\n",
       " 'how',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'who',\n",
       " 'when',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'who',\n",
       " 'who',\n",
       " 'when',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'what',\n",
       " 'how',\n",
       " 'what',\n",
       " 'what',\n",
       " 'in',\n",
       " 'who',\n",
       " 'what',\n",
       " 'what',\n",
       " 'where',\n",
       " 'what',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'what',\n",
       " 'by',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'in',\n",
       " 'is',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'by',\n",
       " 'what',\n",
       " 'what',\n",
       " 'how',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'in',\n",
       " 'what',\n",
       " 'what',\n",
       " 'in',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'how',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'how',\n",
       " 'a',\n",
       " 'how',\n",
       " 'the',\n",
       " 'in',\n",
       " 'is',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'is',\n",
       " 'how',\n",
       " 'if',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'how',\n",
       " 'in',\n",
       " 'complexity',\n",
       " 'how',\n",
       " 'what',\n",
       " 'how',\n",
       " 'what',\n",
       " 'how',\n",
       " 'whose',\n",
       " 'if',\n",
       " 'what',\n",
       " 'how',\n",
       " 'assuming',\n",
       " 'how',\n",
       " 'whose',\n",
       " 'what',\n",
       " 'how',\n",
       " 'what',\n",
       " 'what',\n",
       " 'it',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'which',\n",
       " 'how',\n",
       " 'turing',\n",
       " 'what',\n",
       " 'in',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'in',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'a',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'the',\n",
       " 'complexity',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'how',\n",
       " 'what',\n",
       " 'what',\n",
       " 'how',\n",
       " 'time',\n",
       " 'a',\n",
       " 'what',\n",
       " 'communication',\n",
       " 'decision',\n",
       " 'what',\n",
       " 'what',\n",
       " 'how',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'case',\n",
       " 'what',\n",
       " 'case',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'when',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'classification',\n",
       " 'the',\n",
       " 'which',\n",
       " 'a',\n",
       " 'what',\n",
       " 'how',\n",
       " 'what',\n",
       " 'what',\n",
       " 'when',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'how',\n",
       " 'big',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'how',\n",
       " 'what',\n",
       " 'complexity',\n",
       " 'difficulty',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'concrete',\n",
       " 'a',\n",
       " 'a',\n",
       " 'what',\n",
       " 'decision',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'of',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'ac',\n",
       " 'and',\n",
       " 'what',\n",
       " 'ip',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'in',\n",
       " 'what',\n",
       " 'resources',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'within',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'reduction',\n",
       " 'according',\n",
       " 'what',\n",
       " 'polynomial',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'according',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'the',\n",
       " 'what',\n",
       " 'an',\n",
       " 'a',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'how',\n",
       " 'the',\n",
       " 'complete',\n",
       " 'if',\n",
       " 'if',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'in',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'if',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'who',\n",
       " 'what',\n",
       " 'what',\n",
       " 'who',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'to',\n",
       " 'who',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'the',\n",
       " 'that',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'where',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'where',\n",
       " 'what',\n",
       " 'what',\n",
       " 'in',\n",
       " 'how',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'how',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'though',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'problems',\n",
       " 'intractable',\n",
       " 'if',\n",
       " 'what',\n",
       " 'when',\n",
       " 'what',\n",
       " 'when',\n",
       " 'what',\n",
       " 'what',\n",
       " 'despite',\n",
       " 'what',\n",
       " 'how',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'who',\n",
       " 'what',\n",
       " 'in',\n",
       " 'in',\n",
       " 'what',\n",
       " 'what',\n",
       " 'who',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'in',\n",
       " 'what',\n",
       " 'in',\n",
       " 'what',\n",
       " 'who',\n",
       " 'what',\n",
       " 'what',\n",
       " 'who',\n",
       " 'in',\n",
       " 'in',\n",
       " 'who',\n",
       " 'who',\n",
       " 'what',\n",
       " 'who',\n",
       " 'who',\n",
       " 'what',\n",
       " 'in',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'who',\n",
       " 'what',\n",
       " 'what',\n",
       " 'how',\n",
       " 'who',\n",
       " 'who',\n",
       " 'who',\n",
       " 'who',\n",
       " 'what',\n",
       " 'where',\n",
       " 'what',\n",
       " 'when',\n",
       " 'what',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'who',\n",
       " 'how',\n",
       " 'how',\n",
       " 'the',\n",
       " 'the',\n",
       " 'what',\n",
       " 'what',\n",
       " 'when',\n",
       " 'in',\n",
       " 'what',\n",
       " 'which',\n",
       " 'what',\n",
       " 'in',\n",
       " 'what',\n",
       " 'when',\n",
       " 'who',\n",
       " 'an',\n",
       " 'jean',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'where',\n",
       " 'where',\n",
       " 'what',\n",
       " 'what',\n",
       " 'france',\n",
       " 'what',\n",
       " 'when',\n",
       " 'what',\n",
       " 'what',\n",
       " 'how',\n",
       " 'in',\n",
       " 'in',\n",
       " 'where',\n",
       " 'what',\n",
       " 'who',\n",
       " 'what',\n",
       " 'the',\n",
       " 'in',\n",
       " 'what',\n",
       " 'how',\n",
       " 'what',\n",
       " 'what',\n",
       " 'when',\n",
       " 'who',\n",
       " 'what',\n",
       " 'by',\n",
       " 'the',\n",
       " 'in',\n",
       " 'in',\n",
       " 'where',\n",
       " 'besides',\n",
       " 'in',\n",
       " 'what',\n",
       " 'where',\n",
       " 'when',\n",
       " 'from',\n",
       " 'charleston',\n",
       " 'what',\n",
       " 'what',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'who',\n",
       " 'william',\n",
       " 'what',\n",
       " 'with',\n",
       " 'when',\n",
       " 'in',\n",
       " 'what',\n",
       " 'what',\n",
       " 'in',\n",
       " 'what',\n",
       " 'when',\n",
       " 'which',\n",
       " 'how',\n",
       " 'in',\n",
       " 'how',\n",
       " 'who',\n",
       " 'how',\n",
       " 'what',\n",
       " 'what',\n",
       " 'how',\n",
       " 'how',\n",
       " 'what',\n",
       " 'how',\n",
       " 'how',\n",
       " 'how',\n",
       " 'how',\n",
       " 'what',\n",
       " 'where',\n",
       " 'when',\n",
       " 'what',\n",
       " 'which',\n",
       " 'when',\n",
       " 'in',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'how',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'how',\n",
       " 'how',\n",
       " 'where',\n",
       " 'what',\n",
       " 'how',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'in',\n",
       " 'how',\n",
       " 'how',\n",
       " 'how',\n",
       " 'where',\n",
       " 'where',\n",
       " 'what',\n",
       " 'how',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'how',\n",
       " 'how',\n",
       " 'in',\n",
       " 'how',\n",
       " 'in',\n",
       " 'where',\n",
       " 'by',\n",
       " 'who',\n",
       " 'by',\n",
       " 'what',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'where',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'when',\n",
       " 'in',\n",
       " 'in',\n",
       " 'what',\n",
       " 'which',\n",
       " 'what',\n",
       " 'french',\n",
       " 'where',\n",
       " 'street',\n",
       " 'the',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'the',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'the',\n",
       " 'when',\n",
       " 'in',\n",
       " 'what',\n",
       " 'in',\n",
       " 'who',\n",
       " 'what',\n",
       " 'when',\n",
       " 'what',\n",
       " 'the',\n",
       " 'what',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'what',\n",
       " 'what',\n",
       " 'how',\n",
       " 'how',\n",
       " 'what',\n",
       " 'besides',\n",
       " 'how',\n",
       " 'besides',\n",
       " 'what',\n",
       " 'how',\n",
       " 'how',\n",
       " 'what',\n",
       " 'when',\n",
       " 'what',\n",
       " 'in',\n",
       " 'by',\n",
       " 'how',\n",
       " 'in',\n",
       " 'how',\n",
       " 'how',\n",
       " 'families',\n",
       " 'what',\n",
       " 'where',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'in',\n",
       " 'what',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'what',\n",
       " 'who',\n",
       " 'in',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'when',\n",
       " 'how',\n",
       " 'in',\n",
       " 'how',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'why',\n",
       " 'what',\n",
       " 'what',\n",
       " 'in',\n",
       " 'what',\n",
       " 'what',\n",
       " 'when',\n",
       " 'how',\n",
       " 'which',\n",
       " 'after',\n",
       " 'what',\n",
       " 'against',\n",
       " 'french',\n",
       " 'in',\n",
       " 'how',\n",
       " 'how',\n",
       " 'when',\n",
       " 'in',\n",
       " 'there',\n",
       " 'who',\n",
       " 'what',\n",
       " 'which',\n",
       " 'when',\n",
       " 'in',\n",
       " 'how',\n",
       " 'how',\n",
       " 'from',\n",
       " 'what',\n",
       " 'what',\n",
       " 'which',\n",
       " 'when',\n",
       " 'what',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'what',\n",
       " 'how',\n",
       " 'when',\n",
       " 'how',\n",
       " 'how',\n",
       " 'how',\n",
       " 'in',\n",
       " 'in',\n",
       " 'when',\n",
       " 'who',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'in',\n",
       " 'what',\n",
       " 'in',\n",
       " 'in',\n",
       " 'who',\n",
       " 'what',\n",
       " 'when',\n",
       " 'about',\n",
       " 'who',\n",
       " 'what',\n",
       " 'how',\n",
       " 'how',\n",
       " 'where',\n",
       " 'in',\n",
       " 'how',\n",
       " 'what',\n",
       " 'under',\n",
       " 'which',\n",
       " 'huguenots',\n",
       " 'what',\n",
       " 'in',\n",
       " 'where',\n",
       " 'where',\n",
       " 'what',\n",
       " 'what',\n",
       " 'which',\n",
       " 'which',\n",
       " 'what',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'who',\n",
       " 'in',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'to',\n",
       " 'what',\n",
       " 'what',\n",
       " 'what',\n",
       " 'from',\n",
       " 'what',\n",
       " 'who',\n",
       " 'according',\n",
       " 'other',\n",
       " 'who',\n",
       " 'what',\n",
       " 'what',\n",
       " 'who',\n",
       " 'who',\n",
       " 'where',\n",
       " 'when',\n",
       " 'what',\n",
       " 'what',\n",
       " 'in',\n",
       " 'what',\n",
       " 'in',\n",
       " 'in',\n",
       " 'who',\n",
       " 'when',\n",
       " 'what',\n",
       " 'how',\n",
       " 'when',\n",
       " 'reports',\n",
       " 'how',\n",
       " 'in',\n",
       " 'how',\n",
       " 'how',\n",
       " 'how',\n",
       " 'who',\n",
       " 'how',\n",
       " 'what',\n",
       " 'what',\n",
       " 'the',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'what',\n",
       " 'where',\n",
       " 'from',\n",
       " 'what',\n",
       " 'what',\n",
       " 'who',\n",
       " 'how',\n",
       " 'whose',\n",
       " ...]"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_head = []\n",
    "context_list = []\n",
    "question_list = []\n",
    "ground_truth_answer = []\n",
    "for x, y, y1, y2 in zip(dev_dataset.question_idxs, dev_dataset.context_idxs, dev_dataset.y1s, dev_dataset.y2s):\n",
    "    for i in range(1, len(x)):\n",
    "        if idx2word[x[i].item()] != '--OOV--' and idx2word[x[i].item()] != '--NULL--':\n",
    "            question_head.append(idx2word[x[i].item()].lower())\n",
    "            break\n",
    "    context = idx_to_context(y)\n",
    "    context_list.append(' '.join(context))\n",
    "    question_list.append(' '.join(idx_to_context(x)))\n",
    "    if y1 != 0 and y2 != 0:\n",
    "        ground_truth_answer.append(' '.join(context[y1:y2+1]))\n",
    "    else:\n",
    "        ground_truth_answer.append(' ')\n",
    "question_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "09fe7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_train = list(zip(train_dataset.y1s.numpy(), train_dataset.y2s.numpy()))\n",
    "ys_dev = list(zip(dev_dataset.y1s.numpy(), dev_dataset.y2s.numpy())) \n",
    "df_train = pd.DataFrame(ys_train, columns=['y1', 'y2'])\n",
    "df_dev = pd.DataFrame(ys_dev, columns=['y1', 'y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "9e8cdc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "device, gpu_ids = util.get_available_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6089c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UnifiedQANet(word_vectors=word_vectors,\n",
    "              char_vectors=char_vectors,\n",
    "              hidden_size=128,\n",
    "              num_head=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "281de66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, checkpoint_path, gpu_ids, return_step=True):\n",
    "    device = 'cpu'\n",
    "    ckpt_dict = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "    # Build model, load parameters\n",
    "    model.load_state_dict(ckpt_dict['model_state'], strict=False)\n",
    "\n",
    "    if return_step:\n",
    "        step = ckpt_dict['step']\n",
    "        return model, step\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8de7e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): UnifiedQANet(\n",
       "    (emb): Embedding(\n",
       "      (word_emb): Embedding(88714, 300)\n",
       "      (char_emb): Embedding(1376, 64)\n",
       "      (seg_emb): Embedding(2, 128)\n",
       "      (conv2d): Conv2d(64, 128, kernel_size=(1, 5), stride=(1, 1))\n",
       "      (conv1d_word): FeedForward(\n",
       "        (out): Linear(in_features=300, out_features=128, bias=False)\n",
       "      )\n",
       "      (conv1d): FeedForward(\n",
       "        (out): Linear(in_features=256, out_features=128, bias=False)\n",
       "      )\n",
       "      (hwy): HighwayEncoder(\n",
       "        (transforms): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (gates): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (emb_enc_blks): ModuleList(\n",
       "      (0): EncoderBlock(\n",
       "        (convs): ModuleList(\n",
       "          (0): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), groups=128, bias=False)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), groups=128, bias=False)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), groups=128, bias=False)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), groups=128, bias=False)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (ffn_1): FeedForward(\n",
       "          (out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (ffn_2): FeedForward(\n",
       "          (out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (layer_norm_convs): ModuleList(\n",
       "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm_attention): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm_ffn): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (cq_att): BiDAFAttention()\n",
       "    (proj): FeedForward(\n",
       "      (out): Linear(in_features=512, out_features=128, bias=False)\n",
       "    )\n",
       "    (model_enc_blks): ModuleList(\n",
       "      (0): EncoderBlock(\n",
       "        (convs): ModuleList(\n",
       "          (0): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128, bias=False)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128, bias=False)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (ffn_1): FeedForward(\n",
       "          (out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (ffn_2): FeedForward(\n",
       "          (out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (layer_norm_convs): ModuleList(\n",
       "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm_attention): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm_ffn): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): EncoderBlock(\n",
       "        (convs): ModuleList(\n",
       "          (0): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128, bias=False)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128, bias=False)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (ffn_1): FeedForward(\n",
       "          (out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (ffn_2): FeedForward(\n",
       "          (out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (layer_norm_convs): ModuleList(\n",
       "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm_attention): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm_ffn): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): EncoderBlock(\n",
       "        (convs): ModuleList(\n",
       "          (0): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128, bias=False)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128, bias=False)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (ffn_1): FeedForward(\n",
       "          (out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (ffn_2): FeedForward(\n",
       "          (out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (layer_norm_convs): ModuleList(\n",
       "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm_attention): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm_ffn): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): EncoderBlock(\n",
       "        (convs): ModuleList(\n",
       "          (0): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128, bias=False)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128, bias=False)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (ffn_1): FeedForward(\n",
       "          (out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (ffn_2): FeedForward(\n",
       "          (out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (layer_norm_convs): ModuleList(\n",
       "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm_attention): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm_ffn): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): EncoderBlock(\n",
       "        (convs): ModuleList(\n",
       "          (0): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128, bias=False)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): DepthwiseSeparableConv(\n",
       "            (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128, bias=False)\n",
       "            (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (ffn_1): FeedForward(\n",
       "          (out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (ffn_2): FeedForward(\n",
       "          (out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (layer_norm_convs): ModuleList(\n",
       "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm_attention): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm_ffn): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (out): Output(\n",
       "      (w1): FeedForward(\n",
       "        (out): Linear(in_features=256, out_features=1, bias=False)\n",
       "      )\n",
       "      (w2): FeedForward(\n",
       "        (out): Linear(in_features=256, out_features=1, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.DataParallel(model, gpu_ids)\n",
    "model = load_model(model, 'save/train/uqanet-02/best.pth.tar', None, return_step=False)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41635b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dev_dataset\n",
    "data_loader = data.DataLoader(dataset,\n",
    "                              batch_size=64,\n",
    "                              shuffle=False,\n",
    "                              num_workers=4,\n",
    "                              collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "643ff57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5951/5951 [00:13<00:00, 428.90it/s]\n"
     ]
    }
   ],
   "source": [
    "nll_meter = util.AverageMeter()\n",
    "pred_dict = {}  # Predictions for TensorBoard\n",
    "eval_file = './data/dev_eval.json'\n",
    "with open(eval_file, 'r') as fh:\n",
    "    gold_dict = json_load(fh)\n",
    "with torch.no_grad(), \\\n",
    "        tqdm(total=len(dataset)) as progress_bar:\n",
    "    for cw_idxs, cc_idxs, qw_idxs, qc_idxs, y1, y2, ids in data_loader:\n",
    "        # Setup for forward\n",
    "        cw_idxs = cw_idxs.to(device)\n",
    "        qw_idxs = qw_idxs.to(device)\n",
    "        cc_idxs = cc_idxs.to(device)\n",
    "        qc_idxs = qc_idxs.to(device)\n",
    "        batch_size = cw_idxs.size(0)\n",
    "\n",
    "        # Forward\n",
    "        log_p1, log_p2 = model(cw_idxs, qw_idxs, cc_idxs, qc_idxs)\n",
    "        y1, y2 = y1.to(device), y2.to(device)\n",
    "        loss = F.nll_loss(log_p1, y1) + F.nll_loss(log_p2, y2)\n",
    "        nll_meter.update(loss.item(), batch_size)\n",
    "\n",
    "        # Get F1 and EM scores\n",
    "        p1, p2 = log_p1.exp(), log_p2.exp()\n",
    "        starts, ends = util.discretize(p1, p2, 15, True)\n",
    "\n",
    "        # Log info\n",
    "        progress_bar.update(batch_size)\n",
    "\n",
    "        idx2pred, uuid2pred = util.convert_tokens(gold_dict,\n",
    "                                                  ids.tolist(),\n",
    "                                                  starts.tolist(),\n",
    "                                                  ends.tolist(),\n",
    "                                                  True)\n",
    "        pred_dict.update(idx2pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "022aee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[len(x.split()) for x in pred_dict.values()], question_head, context_list]).T\n",
    "df.columns = ['predicted_len', 'question_head', 'context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "b8ed457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "em = []\n",
    "f1 = []\n",
    "avna = []\n",
    "for key, value in pred_dict.items():\n",
    "    ground_truths = gold_dict[key]['answers']\n",
    "    prediction = value\n",
    "\n",
    "    em.append(metric_max_over_ground_truths(compute_em, prediction, ground_truths))\n",
    "    f1.append(metric_max_over_ground_truths(compute_f1, prediction, ground_truths))\n",
    "    avna.append(compute_avna(prediction, ground_truths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "33e9db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([em, f1, avna, question_head]).T\n",
    "df.columns = ['EM', 'F1', 'AvNA', 'question_head']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "9846beca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EM</th>\n",
       "      <th>F1</th>\n",
       "      <th>AvNA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_head</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\"</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51.6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>why</th>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.676061</td>\n",
       "      <td>0.77381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>william</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>within</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worked</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     EM        F1     AvNA\n",
       "question_head                             \n",
       "\"              1.000000  1.000000  1.00000\n",
       "-              0.000000  0.000000  0.00000\n",
       "1              0.000000  0.000000  0.00000\n",
       "2              0.000000  0.000000  0.00000\n",
       "51.6           1.000000  1.000000  1.00000\n",
       "...                 ...       ...      ...\n",
       "why            0.595238  0.676061  0.77381\n",
       "william        0.000000  0.000000  0.00000\n",
       "with           0.000000  0.800000  1.00000\n",
       "within         1.000000  1.000000  1.00000\n",
       "worked         0.500000  0.500000  0.50000\n",
       "\n",
       "[307 rows x 3 columns]"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('question_head').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "d9e3e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.value_counts(df.question_head).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "914e5668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'who', 'how', 'when', 'where', 'which', 'why']"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_types = ['what', 'who', 'how', 'when', 'where', 'which', 'why']\n",
    "key_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "f8504d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, q in enumerate(question_head):\n",
    "    if q not in key_types or q=='in' or q=='the':\n",
    "        question_head[i] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "50c5037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([em, f1, avna, question_head, context_list, question_list, pred_dict.values(), ground_truth_answer]).T\n",
    "df.columns = ['EM', 'F1', 'AvNA', 'question_head', 'context', 'question', 'pred_answer', 'true_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "d15cbda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EM</th>\n",
       "      <th>F1</th>\n",
       "      <th>AvNA</th>\n",
       "      <th>question_head</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>pred_answer</th>\n",
       "      <th>true_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>other</td>\n",
       "      <td>--OOV-- The Normans ( Norman : --OOV-- ; Frenc...</td>\n",
       "      <td>--OOV-- In what country is Normandy located ? ...</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>when</td>\n",
       "      <td>--OOV-- The Normans ( Norman : --OOV-- ; Frenc...</td>\n",
       "      <td>--OOV-- When were the Normans in Normandy ? --...</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>other</td>\n",
       "      <td>--OOV-- The Normans ( Norman : --OOV-- ; Frenc...</td>\n",
       "      <td>--OOV-- From which countries did the Norse ori...</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "      <td>Denmark , Iceland and Norway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>who</td>\n",
       "      <td>--OOV-- The Normans ( Norman : --OOV-- ; Frenc...</td>\n",
       "      <td>--OOV-- Who was the Norse leader ? --NULL-- --...</td>\n",
       "      <td>Rollo</td>\n",
       "      <td>Rollo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>what</td>\n",
       "      <td>--OOV-- The Normans ( Norman : --OOV-- ; Frenc...</td>\n",
       "      <td>--OOV-- What century did the Normans first gai...</td>\n",
       "      <td>10th</td>\n",
       "      <td>10th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5946</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>what</td>\n",
       "      <td>--OOV-- The pound - force has a metric counter...</td>\n",
       "      <td>--OOV-- What is the seldom used force unit equ...</td>\n",
       "      <td></td>\n",
       "      <td>--OOV--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>what</td>\n",
       "      <td>--OOV-- The pound - force has a metric counter...</td>\n",
       "      <td>--OOV-- What does not have a metric counterpar...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5948</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>what</td>\n",
       "      <td>--OOV-- The pound - force has a metric counter...</td>\n",
       "      <td>--OOV-- What is the force exerted by standard ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>what</td>\n",
       "      <td>--OOV-- The pound - force has a metric counter...</td>\n",
       "      <td>--OOV-- What force leads to a commonly used un...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5950</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>what</td>\n",
       "      <td>--OOV-- The pound - force has a metric counter...</td>\n",
       "      <td>--OOV-- What force is part of the modern SI sy...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5951 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EM   F1 AvNA question_head  \\\n",
       "0     1  1.0  1.0         other   \n",
       "1     1  1.0  1.0          when   \n",
       "2     1  1.0  1.0         other   \n",
       "3     1  1.0  1.0           who   \n",
       "4     1  1.0  1.0          what   \n",
       "...  ..  ...  ...           ...   \n",
       "5946  0    0  0.0          what   \n",
       "5947  1    1  1.0          what   \n",
       "5948  1    1  1.0          what   \n",
       "5949  1    1  1.0          what   \n",
       "5950  1    1  1.0          what   \n",
       "\n",
       "                                                context  \\\n",
       "0     --OOV-- The Normans ( Norman : --OOV-- ; Frenc...   \n",
       "1     --OOV-- The Normans ( Norman : --OOV-- ; Frenc...   \n",
       "2     --OOV-- The Normans ( Norman : --OOV-- ; Frenc...   \n",
       "3     --OOV-- The Normans ( Norman : --OOV-- ; Frenc...   \n",
       "4     --OOV-- The Normans ( Norman : --OOV-- ; Frenc...   \n",
       "...                                                 ...   \n",
       "5946  --OOV-- The pound - force has a metric counter...   \n",
       "5947  --OOV-- The pound - force has a metric counter...   \n",
       "5948  --OOV-- The pound - force has a metric counter...   \n",
       "5949  --OOV-- The pound - force has a metric counter...   \n",
       "5950  --OOV-- The pound - force has a metric counter...   \n",
       "\n",
       "                                               question  \\\n",
       "0     --OOV-- In what country is Normandy located ? ...   \n",
       "1     --OOV-- When were the Normans in Normandy ? --...   \n",
       "2     --OOV-- From which countries did the Norse ori...   \n",
       "3     --OOV-- Who was the Norse leader ? --NULL-- --...   \n",
       "4     --OOV-- What century did the Normans first gai...   \n",
       "...                                                 ...   \n",
       "5946  --OOV-- What is the seldom used force unit equ...   \n",
       "5947  --OOV-- What does not have a metric counterpar...   \n",
       "5948  --OOV-- What is the force exerted by standard ...   \n",
       "5949  --OOV-- What force leads to a commonly used un...   \n",
       "5950  --OOV-- What force is part of the modern SI sy...   \n",
       "\n",
       "                      pred_answer                   true_answer  \n",
       "0                          France                        France  \n",
       "1         10th and 11th centuries       10th and 11th centuries  \n",
       "2     Denmark, Iceland and Norway  Denmark , Iceland and Norway  \n",
       "3                           Rollo                         Rollo  \n",
       "4                            10th                          10th  \n",
       "...                           ...                           ...  \n",
       "5946                                                    --OOV--  \n",
       "5947                                                             \n",
       "5948                                                             \n",
       "5949                                                             \n",
       "5950                                                             \n",
       "\n",
       "[5951 rows x 8 columns]"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "3499ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YIRENZ~1\\AppData\\Local\\Temp/ipykernel_27456/138076888.py:1: FutureWarning: Dropping invalid columns in DataFrameGroupBy.mean is deprecated. In a future version, a TypeError will be raised. Before calling .mean, select only columns which should be valid for the function.\n",
      "  tmp = (df.groupby(\"question_head\").mean()*100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EM</th>\n",
       "      <th>F1</th>\n",
       "      <th>AvNA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_head</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>how</th>\n",
       "      <td>64.952381</td>\n",
       "      <td>69.322802</td>\n",
       "      <td>74.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>63.920208</td>\n",
       "      <td>67.098779</td>\n",
       "      <td>74.674761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>what</th>\n",
       "      <td>66.317311</td>\n",
       "      <td>69.862453</td>\n",
       "      <td>75.966751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>when</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>75.851732</td>\n",
       "      <td>81.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>62.068966</td>\n",
       "      <td>66.595574</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>which</th>\n",
       "      <td>68.493151</td>\n",
       "      <td>74.414052</td>\n",
       "      <td>82.876712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who</th>\n",
       "      <td>67.880795</td>\n",
       "      <td>70.323837</td>\n",
       "      <td>74.503311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>why</th>\n",
       "      <td>59.523810</td>\n",
       "      <td>67.606063</td>\n",
       "      <td>77.380952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      EM         F1       AvNA\n",
       "question_head                                 \n",
       "how            64.952381  69.322802  74.857143\n",
       "other          63.920208  67.098779  74.674761\n",
       "what           66.317311  69.862453  75.966751\n",
       "when           75.000000  75.851732  81.363636\n",
       "where          62.068966  66.595574  75.000000\n",
       "which          68.493151  74.414052  82.876712\n",
       "who            67.880795  70.323837  74.503311\n",
       "why            59.523810  67.606063  77.380952"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = (df.groupby(\"question_head\").mean()*100)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "f0f30ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_head\n",
       "why        84\n",
       "which     146\n",
       "where     232\n",
       "when      440\n",
       "how       525\n",
       "who       604\n",
       "other    1153\n",
       "what     2767\n",
       "Name: EM, dtype: int64"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"question_head\").count()['EM'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "2ac50d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>what</th>\n",
       "      <th>who</th>\n",
       "      <th>how</th>\n",
       "      <th>when</th>\n",
       "      <th>where</th>\n",
       "      <th>which</th>\n",
       "      <th>why</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>66.317311</td>\n",
       "      <td>67.880795</td>\n",
       "      <td>64.952381</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>62.068966</td>\n",
       "      <td>68.493151</td>\n",
       "      <td>59.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>69.862453</td>\n",
       "      <td>70.323837</td>\n",
       "      <td>69.322802</td>\n",
       "      <td>75.851732</td>\n",
       "      <td>66.595574</td>\n",
       "      <td>74.414052</td>\n",
       "      <td>67.606063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AvNA</th>\n",
       "      <td>75.966751</td>\n",
       "      <td>74.503311</td>\n",
       "      <td>74.857143</td>\n",
       "      <td>81.363636</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>82.876712</td>\n",
       "      <td>77.380952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           what        who        how       when      where      which  \\\n",
       "EM    66.317311  67.880795  64.952381  75.000000  62.068966  68.493151   \n",
       "F1    69.862453  70.323837  69.322802  75.851732  66.595574  74.414052   \n",
       "AvNA  75.966751  74.503311  74.857143  81.363636  75.000000  82.876712   \n",
       "\n",
       "            why  \n",
       "EM    59.523810  \n",
       "F1    67.606063  \n",
       "AvNA  77.380952  "
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([tmp.loc[h] for h in key_types]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "9a7ad15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EM</th>\n",
       "      <th>F1</th>\n",
       "      <th>AvNA</th>\n",
       "      <th>question_head</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>pred_answer</th>\n",
       "      <th>true_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [EM, F1, AvNA, question_head, context, question, pred_answer, true_answer]\n",
       "Index: []"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_example = df[(df.question_head == 'the') & (df.EM==0)]#.iloc[2]\n",
    "bad_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "e8bdd552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EM                                                               0\n",
       "F1                                                               0\n",
       "AvNA                                                           0.0\n",
       "question_head                                                 what\n",
       "context          --OOV-- The Norman dynasty had a major politic...\n",
       "question         --OOV-- What type of major impact did the Norm...\n",
       "pred_answer                political, cultural and military impact\n",
       "true_answer                                                       \n",
       "Name: 12, dtype: object"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_example = df[(df.question_head == 'what') & (df.EM==0)].iloc[2]\n",
    "bad_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "119c57f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--OOV-- The Norman dynasty had a major political , cultural and military impact on medieval Europe and even the Near East . The Normans were famed for their martial spirit and eventually for their Christian piety , becoming exponents of the Catholic orthodoxy into which they assimilated . They adopted the Gallo - Romance language of the Frankish land they settled , their dialect becoming known as Norman , --OOV-- or Norman French , an important literary language . The Duchy of Normandy , which they formed by treaty with the French crown , was a great fief of medieval France , and under Richard I of Normandy was forged into a cohesive and formidable principality in feudal tenure . The Normans are noted both for their culture , such as their unique Romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . Norman adventurers founded the Kingdom of Sicily under Roger II after conquering southern Italy on the Saracens and Byzantines , and an expedition on behalf of their duke , William the Conqueror , led to the Norman conquest of England at the Battle of Hastings in 1066 . Norman cultural and military influence spread from these new European centres to the Crusader states of the Near East , where their prince --OOV-- I founded the Principality of Antioch in the Levant , to Scotland and Wales in Great Britain , to Ireland , and to the coasts of north Africa and the Canary Islands . --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL--'"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_example.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "e3f1a795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--OOV-- What type of major impact did the Norman dynasty have on modern Europe ? --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL--'"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_example.question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "d555d1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'political, cultural and military impact'"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_example.pred_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "fd04785f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_example.true_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5284c636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "3910791a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EM                                                               0\n",
       "F1                                                               0\n",
       "AvNA                                                           0.0\n",
       "question_head                                                  why\n",
       "context          --OOV-- The reason for the order of the classe...\n",
       "question         --OOV-- Why were Northern Chinese ranked highe...\n",
       "pred_answer                                                       \n",
       "true_answer                                       they surrendered\n",
       "Name: 3098, dtype: object"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_example = df.iloc[3098]\n",
    "bad_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "2b0fa008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--OOV-- The reason for the order of the classes and the reason why people were placed in a certain class was the date they surrendered to the Mongols , and had nothing to do with their ethnicity . The earlier they surrendered to the Mongols , the higher they were placed , the more the held out , the lower they were ranked . The Northern Chinese were ranked higher and Southern Chinese were ranked lower because southern China withstood and fought to the last before caving in . Major commerce during this era gave rise to favorable conditions for private southern Chinese manufacturers and merchants . --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL--'"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_example.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "111f16fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--OOV-- Why were Northern Chinese ranked higher ? --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL--'"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_example.question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "65263e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_example.pred_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "18df41eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'they surrendered'"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_example.true_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "397f1b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EM                                                               0\n",
       "F1                                                               0\n",
       "AvNA                                                           1.0\n",
       "question_head                                                 when\n",
       "context          --OOV-- Immediately after Decision Time a \" Me...\n",
       "question         --OOV-- When is the Members Debate held ? --NU...\n",
       "pred_answer                                             45 minutes\n",
       "true_answer                        Immediately after Decision Time\n",
       "Name: 3741, dtype: object"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_example = df[(df.question_head == 'when')&(df.EM==0)&(df.F1==0)&(df.pred_answer!= ' ')&(df.true_answer!= ' ')].loc[3741]\n",
    "bad_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "c064da88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--OOV-- Immediately after Decision Time a \" Members Debate \" is held , which lasts for 45 minutes . Members Business is a debate on a motion proposed by an --OOV-- who is not a Scottish minister . Such motions are on issues which may be of interest to a particular area such as a member \\'s own constituency , an upcoming or past event or any other item which would otherwise not be accorded official parliamentary time . As well as the --OOV-- , other members normally contribute to the debate . The relevant minister , whose department the debate and motion relate to \" winds up \" the debate by speaking after all other participants . --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL--'"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_example.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "89969902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--OOV-- When is the Members Debate held ? --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL-- --NULL--'"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_example.question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "e298f521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'45 minutes'"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_example.pred_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "8c7b86b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Immediately after Decision Time'"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_example.true_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05599cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff1718e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (local_nmt)",
   "language": "python",
   "name": "local_nmt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
